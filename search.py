import numpy as np
import torch
import config
from data_loader import load_json_corpus, build_pool
import models
import evaluation

def main():
    # ---------------------------------------------------------
    # 1. ADIM: TÃœM VERÄ° SETÄ°NÄ° YÃœKLE (KÃ¼tÃ¼phaneyi OluÅŸtur)
    # ---------------------------------------------------------
    print("ðŸ“š Veri seti yÃ¼kleniyor...")
    
    # Burada 'limit=None' diyerek tÃ¼m veriyi Ã§ekiyoruz, split yapmÄ±yoruz.
    raw_objs, doc_ids = load_json_corpus(
        data_dir=config.DATA_DIR, # Config dosyasÄ±nda tanÄ±mlÄ± olmalÄ±
        pattern="*.json",         # Senin dosya isimlendirmene gÃ¶re ayarla
        recursive=False
    )

    # Arama Havuzu (Corpus) oluÅŸturuluyor
    # variant="reasoning" veya "full" seÃ§ebilirsin, neyin iÃ§inde arayacaksan.
    _, d_texts, ids_all, _, _ = build_pool(raw_objs, doc_ids, variant="summary_to_reasoning")
    
    print(f"âœ… Toplam {len(d_texts)} adet dokÃ¼man indekslenmeye hazÄ±r.")

    # ---------------------------------------------------------
    # 2. ADIM: MODELLERÄ° HAZIRLA VE Ä°NDEKSLE
    # ---------------------------------------------------------
    print("ðŸ§  Modeller yÃ¼kleniyor ve indeks oluÅŸturuluyor (biraz sÃ¼rebilir)...")
    
    # A) Dense Model (VektÃ¶r)
    model = models.make_st_from_hf(config.HF_MODEL_ID) # Config'den model ismini Ã§eker
    
    # TÃ¼m dokÃ¼manlarÄ±n vektÃ¶rlerini (embedding) bir kere hesapla
    d_embs = models.st_encode(model, d_texts)
    
    # B) Sparse Model (BM25)
    bm25 = evaluation.build_bm25_index(d_texts)
    
    print("ðŸš€ Sistem hazÄ±r! Sorgu bekleniyor...")

    # ---------------------------------------------------------
    # 3. ADIM: CANLI ARAMA DÃ–NGÃœSÃœ
    # ---------------------------------------------------------
    while True:
        print("\n" + "="*50)
        query_text = input("ðŸ” Sorgunuzu girin (Ã‡Ä±kÄ±ÅŸ iÃ§in 'q'): ").strip()
        
        if query_text.lower() == 'q':
            print("Ã‡Ä±kÄ±ÅŸ yapÄ±lÄ±yor...")
            break
        
        if not query_text:
            continue

        # --- ARAMA Ä°ÅžLEMÄ° ---
        
        # 1. VektÃ¶r AramasÄ± Skoru
        q_emb = models.st_encode(model, [query_text]) # (1, 768)
        dense_scores = models.dense_score_matrix(q_emb, d_embs) # (1, N)
        
        # 2. BM25 AramasÄ± Skoru
        bm25_raw = evaluation.bm25_scores(bm25, query_text) # (N,)
        # Boyut uyuÅŸmazlÄ±ÄŸÄ± olmamasÄ± iÃ§in (1, N) formatÄ±na getiriyoruz
        bm25_scores = bm25_raw.reshape(1, -1)
        
        # 3. Hibrit BirleÅŸtirme (Alpha ayarÄ± config'den veya elle)
        # alpha=1.0 sadece BM25, alpha=0.0 sadece VektÃ¶r. 0.5 ikisinin ortasÄ±.
        final_scores = evaluation.hybrid_scores(bm25_scores, dense_scores, alpha=0.5)
        
        # Skoru tek boyuta indir (N,)
        final_scores = final_scores.flatten() 
        
        # --- SONUÃ‡LARI SIRALA VE GÃ–STER ---
        
        top_k = 15
        # En yÃ¼ksek skordan en dÃ¼ÅŸÃ¼ÄŸe sÄ±rala (bÃ¼yÃ¼kten kÃ¼Ã§Ã¼ÄŸe olduÄŸu iÃ§in - ile Ã§arpÄ±p argsort)
        top_indices = np.argsort(-final_scores)[:top_k]
        
        print(f"\nðŸ† En Benzer {top_k} SonuÃ§:\n")
        
        for rank, idx in enumerate(top_indices):
            doc_id = ids_all[idx]
            score = final_scores[idx]
            content = d_texts[idx]
            
            # Ä°Ã§eriÄŸin Ã§ok uzunsa sadece baÅŸÄ±nÄ± gÃ¶sterelim
            preview = content[:300] + "..." if len(content) > 300 else content
            
            print(f"{rank+1}. [Skor: {score:.4f}] Dosya: {doc_id}")
            print(f"   Ä°Ã§erik: {preview}")
            print("-" * 30)

if __name__ == "__main__":
    main()