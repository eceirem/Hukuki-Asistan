{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMV9xmYUzgQHGp3t+zI6s3n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eceirem/Hukuki-Asistan/blob/hibrit_RRF_Cross-Encoder_BM25/hibrit_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdFVLJTt2yy5"
      },
      "source": [
        "# Uygulama ve Arama Motoru (Demonstrasyon)\n",
        "\n",
        "**AmacÄ±: **Bir Ã¶lÃ§Ã¼m yapmaktan ziyade, sistemin canlÄ± bir arama motoru gibi nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± gÃ¶stermek. Ä°lk dÃ¶kÃ¼manÄ±n Ã¶zetini alÄ±r ve ona en yakÄ±n 5 emsali bulup ekrana yazdÄ±rÄ±r.\n",
        "\n",
        "**KullanÄ±lan YÃ¶ntemler: **Segment ayÄ±klama (extract_sections), RRF Fusion ve Cross-Encoder Reranking."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================================\n",
        "# HUKUKÄ° ASÄ°STAN - GELÄ°ÅžMÄ°Åž HÄ°BRÄ°T EMSAL ARAMA MOTORU (v2)\n",
        "# Mimari: BM25 + Bi-Encoder -> RRF Fusion -> Cross-Encoder Rerank\n",
        "# ===========================================================\n",
        "\n",
        "import os, glob, json, re, random\n",
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from typing import Dict, Any, List, Tuple, Optional\n",
        "\n",
        "\n",
        "!pip install -q rank-bm25 sentence-transformers tqdm\n",
        "\n",
        "from rank_bm25 import BM25Okapi\n",
        "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
        "\n",
        "# --- 1. CONFIG & PATHS ---\n",
        "DATA_DIR = \"/content/drive/MyDrive/Legal NLP/Dataset/Structured_Judgements\" # Google Drive yoluna gÃ¶re ayarlÄ± [cite: 43]\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BI_ENCODER_MODEL = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\" # [cite: 123, 208]\n",
        "CROSS_ENCODER_MODEL = \"cross-encoder/ms-marco-MiniLM-L-6-v2\" # Yeniden sÄ±ralama iÃ§in usta dokunuÅŸu\n",
        "\n",
        "# --- 2. VERÄ° YÃœKLEME VE TEMÄ°ZLEME ---\n",
        "def clean_text(s: Any) -> str:\n",
        "    s = \"\" if s is None else str(s)\n",
        "    return re.sub(r\"\\s+\", \" \", s).strip()\n",
        "\n",
        "def load_legal_corpus(data_dir: str):\n",
        "    paths = sorted(glob.glob(os.path.join(data_dir, \"*.json\")))\n",
        "    raw_objs, doc_ids = [], []\n",
        "    for p in tqdm(paths, desc=\"JSON Kararlar YÃ¼kleniyor\"):\n",
        "        with open(p, \"r\", encoding=\"utf-8\") as f:\n",
        "            raw_objs.append(json.load(f))\n",
        "        doc_ids.append(os.path.basename(p))\n",
        "    return raw_objs, doc_ids\n",
        "\n",
        "# Karar bÃ¶lÃ¼mlerini makaleye uygun ÅŸekilde ayÄ±klÄ±yoruz [cite: 38, 99]\n",
        "def extract_sections(obj: Dict[str, Any]):\n",
        "    rrl = obj.get(\"rrl_segments\") or {}\n",
        "    sf  = obj.get(\"structural_features\") or {}\n",
        "    md  = obj.get(\"meta_data\") or {}\n",
        "\n",
        "    return {\n",
        "        \"summary\": clean_text(obj.get(\"summary_for_model\")), # Sorgu olarak kullanÄ±lacak [cite: 126]\n",
        "        \"facts\": clean_text(rrl.get(\"facts_text\")),\n",
        "        \"reasoning\": clean_text(rrl.get(\"reasoning_text\")), # En ayÄ±rt edici bÃ¶lÃ¼m [cite: 15, 190]\n",
        "        \"laws\": \" \".join([clean_text(x) for x in sf.get(\"mentioned_laws\", [])]),\n",
        "        \"full_index\": f\"{rrl.get('facts_text', '')} {rrl.get('reasoning_text', '')} {sf.get('mentioned_laws', '')}\".strip()\n",
        "    }\n",
        "\n",
        "# --- 3. ARAMA VE SIRALAMA ALGORÄ°TMALARI ---\n",
        "\n",
        "# RRF: Ä°ki farklÄ± modelin sÄ±ralamasÄ±nÄ± adil ÅŸekilde birleÅŸtirir\n",
        "def rrf_fusion(ranks_list: List[np.ndarray], k: int = 60):\n",
        "    rrf_scores = np.zeros(ranks_list[0].shape)\n",
        "    for ranks in ranks_list:\n",
        "        rrf_scores += 1.0 / (k + ranks + 1)\n",
        "    return rrf_scores\n",
        "\n",
        "# Cross-Encoder: Ä°lk 50 adayÄ± derinlemesine analiz eder\n",
        "def apply_reranking(ce_model, query, candidates, top_k=10):\n",
        "    pairs = [[query, cand] for cand in candidates]\n",
        "    scores = ce_model.predict(pairs)\n",
        "    return np.argsort(-scores)[:top_k]\n",
        "\n",
        "# --- 4. ANA Ã‡ALIÅžTIRICI (MAIN PIPELINE) ---\n",
        "\n",
        "def main():\n",
        "    # Ensure Google Drive is mounted\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive', force_remount=True)\n",
        "    except ImportError:\n",
        "        print(\"Google Colab environment not detected. Skipping drive mount.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error mounting Google Drive: {e}\")\n",
        "\n",
        "    # 1. Veriyi Oku\n",
        "    raw_objs, doc_ids = load_legal_corpus(DATA_DIR)\n",
        "\n",
        "    if not raw_objs:\n",
        "        print(f\"UYARI: '{DATA_DIR}' dizininden hiÃ§ hukuki karar dosyasÄ± yÃ¼klenemedi. LÃ¼tfen yolun doÄŸru olduÄŸundan ve JSON dosyalarÄ±nÄ±n mevcut olduÄŸundan emin olun.\")\n",
        "        return # Exit if no data is loaded\n",
        "\n",
        "    processed_data = [extract_sections(o) for o in raw_objs]\n",
        "\n",
        "    # Filter out entries where 'reasoning' is empty, as this is used for corpus_texts\n",
        "    filtered_data = [d for i, d in enumerate(processed_data) if d[\"reasoning\"] and doc_ids[i] is not None]\n",
        "    filtered_doc_ids = [doc_ids[i] for i, d in enumerate(processed_data) if d[\"reasoning\"] and doc_ids[i] is not None]\n",
        "\n",
        "    if not filtered_data:\n",
        "        print(\"UYARI: 'GerekÃ§e' (Reasoning) bÃ¶lÃ¼mÃ¼ iÃ§eren geÃ§erli metin bulunamadÄ±. BM25 ve Bi-Encoder indekslemesi yapÄ±lamÄ±yor.\")\n",
        "        return # Exit if no valid data for corpus\n",
        "\n",
        "    # BoÅŸ olmayan sorgularÄ± ve dÃ¶kÃ¼manlarÄ± ayÄ±r [cite: 101]\n",
        "    # 'summary' alanÄ± boÅŸ olmayanlarÄ± alÄ±yoruz\n",
        "    queries = [d[\"summary\"] for d in filtered_data if d[\"summary\"]]\n",
        "\n",
        "    if not queries:\n",
        "        print(\"UYARI: Sorgu iÃ§in kullanÄ±labilecek geÃ§erli 'summary' alanÄ± bulunamadÄ±. Test sorgusu oluÅŸturulamÄ±yor.\")\n",
        "        return # Exit if no queries can be formed\n",
        "\n",
        "    corpus_texts = [d[\"reasoning\"] for d in filtered_data]\n",
        "\n",
        "    # 2. BM25 HazÄ±rla (Kelimeden yakalar) [cite: 118, 119]\n",
        "    tokenized_corpus = [re.findall(r\"\\w+\", text.lower()) for text in corpus_texts]\n",
        "    bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "    # 3. Bi-Encoder HazÄ±rla (Anlamdan yakalar) [cite: 122, 210]\n",
        "    bi_model = SentenceTransformer(BI_ENCODER_MODEL, device=DEVICE)\n",
        "    doc_embeddings = bi_model.encode(corpus_texts, convert_to_numpy=True, show_progress_bar=True)\n",
        "    ce_model = CrossEncoder(CROSS_ENCODER_MODEL, device=DEVICE)\n",
        "\n",
        "    # 4. Ã–rnek Bir Sorgu Ãœzerinde Test Et\n",
        "    test_query = queries[0]\n",
        "    print(f\"\\nSorgu (Summary for Model): {test_query[:150]}...\\n\")\n",
        "\n",
        "    # A) BM25 SkorlarÄ± ve SÄ±ralamasÄ±\n",
        "    bm25_scores = bm25.get_scores(re.findall(r\"\\w+\", test_query.lower()))\n",
        "    bm25_ranks = np.argsort(np.argsort(-bm25_scores))\n",
        "\n",
        "    # B) Dense (Bi-Encoder) SkorlarÄ± ve SÄ±ralamasÄ±\n",
        "    query_emb = bi_model.encode(test_query)\n",
        "    dense_scores = query_emb @ doc_embeddings.T\n",
        "    dense_ranks = np.argsort(np.argsort(-dense_scores))\n",
        "\n",
        "    # C) RRF Hibrit BirleÅŸtirme (Yenilik!) [cite: 141, 194]\n",
        "    combined_scores = rrf_fusion([bm25_ranks, dense_ranks])\n",
        "    top_50_indices = np.argsort(-combined_scores)[:50]\n",
        "\n",
        "    # D) Cross-Encoder Reranking (En Ãœst DÃ¼zey Hassasiyet)\n",
        "    candidate_texts = [corpus_texts[idx] for idx in top_50_indices]\n",
        "    reranked_sub_indices = apply_reranking(ce_model, test_query, candidate_texts, top_k=5)\n",
        "    final_indices = top_50_indices[reranked_sub_indices]\n",
        "\n",
        "    # 5. SonuÃ§larÄ± YazdÄ±r\n",
        "    print(\"--- EN YAKIN EMSAL KARARLAR ---\")\n",
        "    for i, idx in enumerate(final_indices):\n",
        "        print(f\"{i+1}. Dosya: {filtered_doc_ids[idx]} | Skor (RRF): {combined_scores[idx]:.4f}\")\n",
        "        print(f\"   GerekÃ§e Ã–zeti: {corpus_texts[idx][:200]}...\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "5MTkjpKmhVRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GHOs6if2qwl"
      },
      "source": [
        "# Performans Ã–lÃ§Ã¼m Paneli (HÄ±zlÄ± Benchmark)\n",
        "\n",
        "**AmacÄ±: **Kod 1 ile neredeyse aynÄ±dÄ±r ancak veri yÃ¼kleme ve iÅŸleme kÄ±sÄ±mlarÄ± daha sadedir. Kod 1'in daha doÄŸrudan ve hÄ±zlÄ± Ã§alÄ±ÅŸan bir versiyonudur.\n",
        "\n",
        "**KullanÄ±lan YÃ¶ntemler: **BM25, Bi-Encoder ve Cross-Encoder."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, json, re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm # DÃ¶ngÃ¼leri izlemek iÃ§in usta dokunuÅŸu\n",
        "import torch\n",
        "from rank_bm25 import BM25Okapi\n",
        "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
        "\n",
        "# --- 1. AYARLAR VE YOLLAR ---\n",
        "DATA_DIR = \"/content/drive/MyDrive/Legal NLP/Dataset/Structured_Judgements\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "BI_ENCODER_MODEL = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
        "CROSS_ENCODER_MODEL = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
        "\n",
        "# --- 2. EVALUATION FONKSÄ°YONU ---\n",
        "def calculate_recall_at_k(ranks, k_values=[1, 5, 10]):\n",
        "    results = {}\n",
        "    for k in k_values:\n",
        "        hits = sum(1 for r in ranks if r < k)\n",
        "        results[f\"R@{k}\"] = round(hits / len(ranks), 4)\n",
        "    return results\n",
        "\n",
        "# --- 3. ANA BENCHMARK FONKSÄ°YONU ---\n",
        "def run_benchmark():\n",
        "    # A) Dosya YÃ¼kleme\n",
        "    paths = sorted(glob.glob(os.path.join(DATA_DIR, \"*.json\")))\n",
        "    corpus_data = []\n",
        "\n",
        "    for p in tqdm(paths, desc=\"1. Dosyalar Diskten Okunuyor\"):\n",
        "        with open(p, \"r\", encoding=\"utf-8\") as f:\n",
        "            obj = json.load(f)\n",
        "            rrl = obj.get(\"rrl_segments\", {})\n",
        "            corpus_data.append({\n",
        "                \"id\": os.path.basename(p),\n",
        "                \"query\": obj.get(\"summary_for_model\", \"\"),\n",
        "                \"reasoning\": rrl.get(\"reasoning_text\", \"\"),\n",
        "            })\n",
        "\n",
        "    # B) Filtreleme\n",
        "    valid_data = [d for d in corpus_data if d[\"query\"] and d[\"reasoning\"]]\n",
        "    queries = [d[\"query\"] for d in valid_data]\n",
        "    docs = [d[\"reasoning\"] for d in valid_data]\n",
        "    total = len(queries)\n",
        "\n",
        "    print(f\"\\nâœ… Veri HazÄ±r: {total} geÃ§erli dÃ¶kÃ¼man/sorgu bulundu.\\n\")\n",
        "\n",
        "    # --- MODEL 1: BM25 (Sparse) ---\n",
        "    print(\"ðŸš€ AdÄ±m 1: BM25 (Kelime BazlÄ±) Analizi BaÅŸlÄ±yor...\")\n",
        "    tokenized_corpus = [re.findall(r\"\\w+\", d.lower()) for d in docs]\n",
        "    bm25 = BM25Okapi(tokenized_corpus)\n",
        "    bm25_ranks = []\n",
        "    for i, q in tqdm(enumerate(queries), total=total, desc=\"   BM25 SÄ±ralanÄ±yor\"):\n",
        "        scores = bm25.get_scores(re.findall(r\"\\w+\", q.lower()))\n",
        "        rank = np.argsort(-scores).tolist().index(i)\n",
        "        bm25_ranks.append(rank)\n",
        "\n",
        "    results_bm25 = calculate_recall_at_k(bm25_ranks)\n",
        "    results_bm25[\"Model\"] = \"BM25 (Reasoning)\"\n",
        "\n",
        "    # --- MODEL 2: BI-ENCODER (Dense) ---\n",
        "    print(\"\\nðŸš€ AdÄ±m 2: Bi-Encoder (Anlamsal) Analizi BaÅŸlÄ±yor...\")\n",
        "    bi_model = SentenceTransformer(BI_ENCODER_MODEL, device=DEVICE)\n",
        "\n",
        "    # Encoding aÅŸamasÄ±nÄ± izle\n",
        "    print(\"   VektÃ¶rler oluÅŸturuluyor (Bu aÅŸama GPU hÄ±zÄ±na baÄŸlÄ±dÄ±r)...\")\n",
        "    doc_embs = bi_model.encode(docs, convert_to_numpy=True, show_progress_bar=True)\n",
        "    query_embs = bi_model.encode(queries, convert_to_numpy=True, show_progress_bar=True)\n",
        "\n",
        "    bi_ranks = []\n",
        "    for i in tqdm(range(total), desc=\"   VektÃ¶rler KarÅŸÄ±laÅŸtÄ±rÄ±lÄ±yor\"):\n",
        "        scores = query_embs[i] @ doc_embs.T\n",
        "        rank = np.argsort(-scores).tolist().index(i)\n",
        "        bi_ranks.append(rank)\n",
        "\n",
        "    results_bi = calculate_recall_at_k(bi_ranks)\n",
        "    results_bi[\"Model\"] = \"Dense (MPNet)\"\n",
        "\n",
        "    # --- MODEL 3: HÄ°BRÄ°T + CROSS-ENCODER (Usta Ä°ÅŸi) ---\n",
        "    print(\"\\nðŸš€ AdÄ±m 3: Hibrit + Cross-Encoder Re-rank BaÅŸlÄ±yor...\")\n",
        "    print(\"   âš ï¸ UYARI: Bu aÅŸama en aÄŸÄ±r olanÄ±dÄ±r, derinlemesine analiz yapar.\")\n",
        "    ce_model = CrossEncoder(CROSS_ENCODER_MODEL, device=DEVICE)\n",
        "    final_ranks = []\n",
        "    K = 60\n",
        "\n",
        "    # Ana dÃ¶ngÃ¼yÃ¼ izle\n",
        "    for i in tqdm(range(total), desc=\"   Derin Analiz (Re-ranking)\"):\n",
        "        # 1. BM25 & Dense skorlarÄ±nÄ± al\n",
        "        b_scores = bm25.get_scores(re.findall(r\"\\w+\", queries[i].lower()))\n",
        "        b_rank_indices = np.argsort(-b_scores)\n",
        "        d_scores = query_embs[i] @ doc_embs.T\n",
        "        d_rank_indices = np.argsort(-d_scores)\n",
        "\n",
        "        # 2. RRF Fusion\n",
        "        rrf_scores = np.zeros(total)\n",
        "        for rank, idx in enumerate(b_rank_indices): rrf_scores[idx] += 1 / (K + rank + 1)\n",
        "        for rank, idx in enumerate(d_rank_indices): rrf_scores[idx] += 1 / (K + rank + 1)\n",
        "\n",
        "        # 3. Ä°lk 20 adayÄ± Cross-Encoder'a gÃ¶nder\n",
        "        top_20_candidates = np.argsort(-rrf_scores)[:20]\n",
        "        pairs = [[queries[i], docs[idx]] for idx in top_20_candidates]\n",
        "        ce_scores = ce_model.predict(pairs, show_progress_bar=False) # Her adÄ±mda iÃ§ bar gerekmez\n",
        "\n",
        "        # 4. Final SÄ±ralama\n",
        "        best_within_top20 = np.argsort(-ce_scores)\n",
        "        final_top_indices = top_20_candidates[best_within_top20]\n",
        "\n",
        "        if i in final_top_indices:\n",
        "            rank = final_top_indices.tolist().index(i)\n",
        "        else:\n",
        "            rank = 999\n",
        "        final_ranks.append(rank)\n",
        "\n",
        "    results_hybrid = calculate_recall_at_k(final_ranks)\n",
        "    results_hybrid[\"Model\"] = \"Bizim Hibrit (RRF + CE)\"\n",
        "\n",
        "    # --- SONUÃ‡LARI TABLOLAÅžTIR ---\n",
        "    df = pd.DataFrame([results_bm25, results_bi, results_hybrid])\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"ðŸ“Š TEST SONUÃ‡LARI TAMAMLANDI\")\n",
        "    print(\"=\"*50)\n",
        "    return df[[\"Model\", \"R@1\", \"R@5\", \"R@10\"]]\n",
        "\n",
        "# --- Ã‡ALIÅžTIR ---\n",
        "comparison_table = run_benchmark()\n",
        "print(comparison_table)"
      ],
      "metadata": {
        "id": "Gv5k_xxahgyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87EoHidLNnY3"
      },
      "source": [
        "# GeliÅŸtirilmiÅŸ Benchmark Kodu\n",
        "\n",
        "**AmacÄ±:** Sistemdeki tÃ¼m modelleri (BM25, Dense ve Hibrit) veri setinin tamamÄ±nda test edip \"Hangi model daha baÅŸarÄ±lÄ±?\" sorusuna bilimsel (Recall@K) yanÄ±t vermek.\n",
        "\n",
        "**KullanÄ±lan YÃ¶ntemler:** BM25 (Kelime bazlÄ±), MPNet (Anlamsal/VektÃ¶rel), RRF (SÄ±ralama BirleÅŸtirme) ve Cross-Encoder (Yeniden SÄ±ralama).\n",
        "\n",
        "**Ã–ne Ã‡Ä±kan Ã–zelliÄŸi:** Hata payÄ±nÄ± minimize eden temizlik fonksiyonlarÄ± (clean_text) ve dÃ¶kÃ¼manlarÄ±n listede bulunamamasÄ± durumuna karÅŸÄ± korumalÄ± bir yapÄ± iÃ§erir."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, json, re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm # DÃ¶ngÃ¼leri izlemek iÃ§in usta dokunuÅŸu\n",
        "import torch\n",
        "from rank_bm25 import BM25Okapi\n",
        "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
        "from typing import Any\n",
        "from google.colab import drive # Import drive for mounting\n",
        "\n",
        "# --- 1. AYARLAR VE YOLLAR ---\n",
        "DATA_DIR = \"/content/drive/MyDrive/Legal NLP/Dataset/Structured_Judgements\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "BI_ENCODER_MODEL = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
        "CROSS_ENCODER_MODEL = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
        "\n",
        "# --- YardÄ±mcÄ± Fonksiyon: Metin Temizleme ---\n",
        "def clean_text(s: Any) -> str:\n",
        "    s = \"\" if s is None else str(s)\n",
        "    return re.sub(r\"\\s+\", \" \", s).strip()\n",
        "\n",
        "# --- 2. EVALUATION FONKSÄ°YONU ---\n",
        "def calculate_recall_at_k(ranks, k_values=[1, 5, 10]):\n",
        "    results = {}\n",
        "    for k in k_values:\n",
        "        hits = sum(1 for r in ranks if r < k)\n",
        "        results[f\"R@{k}\"] = round(hits / len(ranks), 4)\n",
        "    return results\n",
        "\n",
        "# --- 3. ANA BENCHMARK FONKSÄ°YONU ---\n",
        "def run_benchmark():\n",
        "    # Ensure Google Drive is mounted\n",
        "    try:\n",
        "        drive.mount('/content/drive', force_remount=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error mounting Google Drive: {e}\")\n",
        "        return pd.DataFrame(columns=[\"Model\", \"R@1\", \"R@5\", \"R@10\"]) # Exit if mount fails\n",
        "\n",
        "    # A) Dosya YÃ¼kleme\n",
        "    paths = sorted(glob.glob(os.path.join(DATA_DIR, \"*.json\")))\n",
        "    corpus_data = []\n",
        "\n",
        "    if not paths:\n",
        "        print(f\"UYARI: '{DATA_DIR}' dizininde hiÃ§ hukuki karar dosyasÄ± bulunamadÄ±.\")\n",
        "        return pd.DataFrame(columns=[\"Model\", \"R@1\", \"R@5\", \"R@10\"])\n",
        "\n",
        "    for p in tqdm(paths, desc=\"1. Dosyalar Diskten Okunuyor\"):\n",
        "        with open(p, \"r\", encoding=\"utf-8\") as f:\n",
        "            obj = json.load(f)\n",
        "            rrl = obj.get(\"rrl_segments\", {})\n",
        "            corpus_data.append({\n",
        "                \"id\": os.path.basename(p),\n",
        "                \"query\": clean_text(obj.get(\"summary_for_model\", \"\")),\n",
        "                \"reasoning\": clean_text(rrl.get(\"reasoning_text\", \"\")),\n",
        "            })\n",
        "\n",
        "    # B) Filtreleme\n",
        "    valid_data = [d for d in corpus_data if d[\"query\"] and d[\"reasoning\"]]\n",
        "    queries = [d[\"query\"] for d in valid_data]\n",
        "    docs = [d[\"reasoning\"] for d in valid_data]\n",
        "    total = len(queries)\n",
        "\n",
        "    print(f\"\\nâœ… Veri HazÄ±r: {total} geÃ§erli dÃ¶kÃ¼man/sorgu bulundu.\\n\")\n",
        "\n",
        "    if total == 0:\n",
        "        print(\"UYARI: HiÃ§ geÃ§erli sorgu veya dokÃ¼man bulunamadÄ±. Benchmark Ã§alÄ±ÅŸtÄ±rÄ±lamÄ±yor.\")\n",
        "        return pd.DataFrame(columns=[\"Model\", \"R@1\", \"R@5\", \"R@10\"]) # BoÅŸ DataFrame dÃ¶ndÃ¼r\n",
        "\n",
        "    # --- MODEL 1: BM25 (Sparse) ---\n",
        "    print(\"ðŸš€ AdÄ±m 1: BM25 (Kelime BazlÄ±) Analizi BaÅŸlÄ±yor...\")\n",
        "    tokenized_corpus = [re.findall(r\"\\w+\", d.lower()) for d in docs]\n",
        "    bm25 = BM25Okapi(tokenized_corpus)\n",
        "    bm25_ranks = []\n",
        "    for i, q in tqdm(enumerate(queries), total=total, desc=\"   BM25 SÄ±ralanÄ±yor\"):\n",
        "        tokenized_query = re.findall(r\"\\w+\", q.lower())\n",
        "        if not tokenized_query: # BoÅŸ sorgularÄ± ele al\n",
        "            bm25_ranks.append(999) # Ã‡ok dÃ¼ÅŸÃ¼k bir sÄ±ralama ver\n",
        "            continue\n",
        "        scores = bm25.get_scores(tokenized_query)\n",
        "        rank_list = np.argsort(-scores).tolist()\n",
        "        # EÄŸer mevcut dÃ¶kÃ¼man (i) sÄ±ralama listesinde deÄŸilse veya BM25 sonucu anlamsÄ±zsa\n",
        "        # GÃ¼venli eriÅŸim iÃ§in kontrol ekle: i'nin rank_list iÃ§inde olduÄŸundan emin ol\n",
        "        if i < len(rank_list) and i in rank_list:\n",
        "            rank = rank_list.index(i)\n",
        "        else:\n",
        "            rank = 999\n",
        "        bm25_ranks.append(rank)\n",
        "\n",
        "    results_bm25 = calculate_recall_at_k(bm25_ranks)\n",
        "    results_bm25[\"Model\"] = \"BM25 (Reasoning)\"\n",
        "\n",
        "    # --- MODEL 2: BI-ENCODER (Dense) ---\n",
        "    print(\"\\nðŸš€ AdÄ±m 2: Bi-Encoder (Anlamsal) Analizi BaÅŸlÄ±yor...\")\n",
        "    bi_model = SentenceTransformer(BI_ENCODER_MODEL, device=DEVICE)\n",
        "\n",
        "    # Encoding aÅŸamasÄ±nÄ± izle\n",
        "    print(\"   VektÃ¶rler oluÅŸturuluyor (Bu aÅŸama GPU hÄ±zÄ±na baÄŸlÄ±dÄ±r)...\")\n",
        "    doc_embs = bi_model.encode(docs, convert_to_numpy=True, show_progress_bar=True)\n",
        "    query_embs = bi_model.encode(queries, convert_to_numpy=True, show_progress_bar=True)\n",
        "\n",
        "    bi_ranks = []\n",
        "    for i in tqdm(range(total), desc=\"   VektÃ¶rler KarÅŸÄ±laÅŸtÄ±rÄ±lÄ±yor\"):\n",
        "        scores = query_embs[i] @ doc_embs.T\n",
        "        rank = np.argsort(-scores).tolist().index(i)\n",
        "        bi_ranks.append(rank)\n",
        "\n",
        "    results_bi = calculate_recall_at_k(bi_ranks)\n",
        "    results_bi[\"Model\"] = \"Dense (MPNet)\"\n",
        "\n",
        "    # --- MODEL 3: HÄ°BRÄ°T + CROSS-ENCODER (Usta Ä°ÅŸi) ---\n",
        "    print(\"\\nðŸš€ AdÄ±m 3: Hibrit + Cross-Encoder Re-rank BaÅŸlÄ±yor...\")\n",
        "    print(\"   âš ï¸ UYARI: Bu aÅŸama en aÄŸÄ±r olanÄ±dÄ±r, derinlemesine analiz yapar.\")\n",
        "    ce_model = CrossEncoder(CROSS_ENCODER_MODEL, device=DEVICE)\n",
        "    final_ranks = []\n",
        "    K = 60\n",
        "\n",
        "    # Ana dÃ¶ngÃ¼yÃ¼ izle\n",
        "    for i in tqdm(range(total), desc=\"   Derin Analiz (Re-ranking)\"):\n",
        "        # 1. BM25 & Dense skorlarÄ±nÄ± al\n",
        "        b_scores = bm25.get_scores(re.findall(r\"\\w+\", queries[i].lower()))\n",
        "        b_rank_indices = np.argsort(-b_scores)\n",
        "        d_scores = query_embs[i] @ doc_embs.T\n",
        "        d_rank_indices = np.argsort(-d_scores)\n",
        "\n",
        "        # 2. RRF Fusion\n",
        "        rrf_scores = np.zeros(total)\n",
        "        # BoÅŸ BM25 sorgularÄ±nÄ± ele al, aksi takdirde rrf_scores'a katkÄ± saÄŸlamaz\n",
        "        if re.findall(r\"\\w+\", queries[i].lower()): # YalnÄ±zca token'lar varsa katkÄ± saÄŸla\n",
        "            for rank, idx in enumerate(b_rank_indices): rrf_scores[idx] += 1 / (K + rank + 1)\n",
        "        for rank, idx in enumerate(d_rank_indices): rrf_scores[idx] += 1 / (K + rank + 1)\n",
        "\n",
        "        # 3. Ä°lk 20 adayÄ± Cross-Encoder'a gÃ¶nder\n",
        "        top_20_candidates = np.argsort(-rrf_scores)[:20]\n",
        "        pairs = [[queries[i], docs[idx]] for idx in top_20_candidates]\n",
        "        ce_scores = ce_model.predict(pairs, show_progress_bar=False) # Her adÄ±mda iÃ§ bar gerekmez\n",
        "\n",
        "        # 4. Final SÄ±ralama\n",
        "        best_within_top20 = np.argsort(-ce_scores)\n",
        "        final_top_indices = top_20_candidates[best_within_top20]\n",
        "\n",
        "        if i in final_top_indices:\n",
        "            rank = final_top_indices.tolist().index(i)\n",
        "        else:\n",
        "            rank = 999\n",
        "        final_ranks.append(rank)\n",
        "\n",
        "    results_hybrid = calculate_recall_at_k(final_ranks)\n",
        "    results_hybrid[\"Model\"] = \"Bizim Hibrit (RRF + CE)\"\n",
        "\n",
        "    # --- SONUÃ‡LARI TABLOLAÅžTIR ---\n",
        "    df = pd.DataFrame([results_bm25, results_bi, results_hybrid])\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"ðŸ“Š TEST SONUÃ‡LARI TAMAMLANDI\")\n",
        "    print(\"=\"*50)\n",
        "    return df[[\"Model\", \"R@1\", \"R@5\", \"R@10\"]]\n",
        "\n",
        "# --- Ã‡ALIÅžTIR ---\n",
        "comparison_table = run_benchmark()\n",
        "print(comparison_table)"
      ],
      "metadata": {
        "id": "z4r3blxNhlvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaY3lFlw255c"
      },
      "source": [
        "# ULTIMATE BENCHMARK (PARM + CROSS-ENCODER)\n",
        "\n",
        "**AmacÄ±:** Uzun hukuk metinlerindeki \"anlam seyrelmesi\" sorununu aÅŸmak iÃ§in dÃ¶kÃ¼manlarÄ± parÃ§alara bÃ¶lerek (chunking) en hassas ve derinlemesine emsal tespitini gerÃ§ekleÅŸtirir.\n",
        "\n",
        "**KullanÄ±lan YÃ¶ntemler:** Paragraph Chunking, PARM (MaxSim Pooling) ve Cross-Encoder Reranking."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# HUKUKÄ° ASÄ°STAN - ULTIMATE BENCHMARK (PARM + CROSS-ENCODER)\n",
        "# Mimari: BM25, Bi-Encoder, PARM (Chunking) ve Cross-Encoder\n",
        "# ============================================================\n",
        "\n",
        "import os, glob, json, re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "from rank_bm25 import BM25Okapi\n",
        "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
        "\n",
        "# --- 1. AYARLAR ---\n",
        "DATA_DIR = \"/content/drive/MyDrive/Legal NLP/Dataset/Structured_Judgements\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BI_MODEL = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
        "CE_MODEL = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
        "\n",
        "# 2. CHUNKING FONKSÄ°YONU (PARM'Ä±n Kalbi)\n",
        "def get_chunks(text, chunk_size=250):\n",
        "    \"\"\"Metni paragraf benzeri kÃ¼Ã§Ã¼k parÃ§alara bÃ¶ler.\"\"\"\n",
        "    words = text.split()\n",
        "    if not words: return [\"\"]\n",
        "    return [\" \".join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n",
        "\n",
        "def run_ultimate_benchmark():\n",
        "    # A) VERÄ° YÃœKLEME\n",
        "    paths = sorted(glob.glob(os.path.join(DATA_DIR, \"*.json\")))\n",
        "    all_data = []\n",
        "\n",
        "    for p in tqdm(paths, desc=\"1. Dosyalar Okunuyor\"):\n",
        "        with open(p, \"r\", encoding=\"utf-8\") as f:\n",
        "            obj = json.load(f)\n",
        "            reasoning = obj.get(\"rrl_segments\", {}).get(\"reasoning_text\", \"\")\n",
        "            summary = obj.get(\"summary_for_model\", \"\")\n",
        "            if summary and reasoning:\n",
        "                all_data.append({\n",
        "                    \"id\": os.path.basename(p),\n",
        "                    \"query\": summary,\n",
        "                    \"doc\": reasoning,\n",
        "                    \"chunks\": get_chunks(reasoning) # PARM iÃ§in dÃ¶kÃ¼manÄ± bÃ¶ldÃ¼k\n",
        "                })\n",
        "\n",
        "    total = len(all_data)\n",
        "    queries = [d[\"query\"] for d in all_data]\n",
        "    docs = [d[\"doc\"] for d in all_data]\n",
        "\n",
        "    # MODELLERÄ° YÃœKLE\n",
        "    bi_model = SentenceTransformer(BI_MODEL, device=DEVICE)\n",
        "    ce_model = CrossEncoder(CE_MODEL, device=DEVICE)\n",
        "\n",
        "    # B) VEKTÃ–RLEÅžTÄ°RME\n",
        "    print(\"\\nðŸš€ AdÄ±m 2: VektÃ¶rler OluÅŸturuluyor...\")\n",
        "    query_embs = bi_model.encode(queries, convert_to_numpy=True, show_progress_bar=True)\n",
        "    doc_embs = bi_model.encode(docs, convert_to_numpy=True, show_progress_bar=True)\n",
        "\n",
        "    # --- MODEL: PARM (Ä°NOVATÄ°F) ---\n",
        "    print(\"\\nðŸš€ AdÄ±m 3: PARM (Paragraph Aggregation) Ã–lÃ§Ã¼lÃ¼yor...\")\n",
        "    parm_ranks = []\n",
        "    for i in tqdm(range(total), desc=\"   PARM Analizi\"):\n",
        "        q_emb = query_embs[i]\n",
        "        doc_max_scores = []\n",
        "        for d_entry in all_data:\n",
        "            # DÃ¶kÃ¼manÄ±n her bir chunk'Ä±nÄ± sorguyla kÄ±yasla\n",
        "            chunk_embs = bi_model.encode(d_entry[\"chunks\"], convert_to_numpy=True, show_progress_bar=False)\n",
        "            chunk_scores = q_emb @ chunk_embs.T\n",
        "            doc_max_scores.append(np.max(chunk_scores)) # MAX POOLING: En iyi paragrafÄ±n puanÄ±nÄ± al\n",
        "        parm_ranks.append(np.argsort(-np.array(doc_max_scores)).tolist().index(i))\n",
        "\n",
        "    # --- MODEL: HÄ°BRÄ°T + CROSS-ENCODER ---\n",
        "    print(\"\\nðŸš€ AdÄ±m 4: Hibrit + Cross-Encoder Ã–lÃ§Ã¼lÃ¼yor...\")\n",
        "    final_ranks = []\n",
        "    for i in tqdm(range(total), desc=\"   Re-ranking Analizi\"):\n",
        "        initial_scores = query_embs[i] @ doc_embs.T\n",
        "        top_20_indices = np.argsort(-initial_scores)[:20]\n",
        "\n",
        "        candidates = [docs[idx] for idx in top_20_indices]\n",
        "        pairs = [[queries[i], cand[:1000]] for cand in candidates] # Ä°lk 1000 karakter (HÄ±z iÃ§in)\n",
        "        ce_scores = ce_model.predict(pairs, show_progress_bar=False)\n",
        "\n",
        "        reranked_indices = top_20_indices[np.argsort(-ce_scores)]\n",
        "        final_ranks.append(reranked_indices.tolist().index(i) if i in reranked_indices else 999)\n",
        "\n",
        "    # SONUÃ‡LARI TABLOLAÅžTIR\n",
        "    def get_metrics(ranks, name):\n",
        "        return {\"Model\": name,\n",
        "                \"R@1\": round(sum(1 for r in ranks if r < 1)/len(ranks), 4),\n",
        "                \"R@5\": round(sum(1 for r in ranks if r < 5)/len(ranks), 4),\n",
        "                \"R@10\": round(sum(1 for r in ranks if r < 10)/len(ranks), 4)}\n",
        "\n",
        "    df = pd.DataFrame([\n",
        "        get_metrics(parm_ranks, \"PARM (Paragraph Aggregation)\"),\n",
        "        get_metrics(final_ranks, \"Hibrit + Cross-Encoder (CE)\")\n",
        "    ])\n",
        "    return df\n",
        "\n",
        "# Ã‡ALIÅžTIR\n",
        "results = run_ultimate_benchmark()\n",
        "print(results)"
      ],
      "metadata": {
        "id": "c8-POKv9hqDh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}